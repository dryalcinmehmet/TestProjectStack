version: '2'
services:
  web:
    image: djangoapp
    restart: always
    build:
      context: ./source
      dockerfile: Dockerfile
    command: gunicorn source.wsgi:application --bind 0.0.0.0:8000
    volumes:
      - static_volume:/home/source/web/staticfiles
      - media_volume:/home/source/web/mediafiles
      - .:/app
    env_file:
      - ./.env.prod
    depends_on:
      - db
      - elasticsearch
      - kibana
    environment:
      - LOGSTASH_HOST=logstash
    expose:
      - 5959
    logging:
      driver: "json-file"
    links:
      -elasticsearch
      -kibana
      -airflow
  db:
    image: postgres:12.0-alpine
    volumes:
      - postgres_data:/var/lib/postgresql/data/
    env_file:
      - ./.env.prod.db
  nginx:
    restart: always
    build: ./nginx
    volumes:
      - ./nginx:/etc/nginx/conf.d
      - static_volume:/home/source/web/staticfiles
      - media_volume:/home/source/web/mediafiles
    ports:
      - 80:80
    depends_on:
      - web
  elasticsearch:
    labels:
      com.example.service: "elasticsearch"
      com.example.description: "For searching and indexing data"
    image: docker.elastic.co/elasticsearch/elasticsearch:7.4.2
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - network.publish_host=0.0.0.0
    volumes:
      - type: volume
        source: esdata
        target: /usr/share/elasticsearch/data/
    ports:
      - 9200:9200
  kibana:
    labels:
      com.example.service: "kibana"
      com.example.description: "Data visualisation and for log aggregation"
    image: kibana:7.4.2
    container_name: kibana
    ports:
      - 5601:5601
    environment:
      - ELASTICSEARCH_URL=http://elasticsearch:9200
    depends_on:
      - elasticsearch
  logstash:
    labels:
      com.example.service: "logstash"
      com.example.description: "For logging data"
    image: logstash:7.4.2
    volumes:
      - ./:/logstash_dir
    command: logstash -f /elk/logstash.conf
    depends_on:
      - elasticsearch
    ports:
      - 5959:5959
  postgres:
    image: postgres:12.0-alpine
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
    ports:
      - 5433:5433
  webserver:
    image: puckel/docker-airflow:1.10.6
    build:
      context: ./source/airflow
      dockerfile: Dockerfile
    restart: always
    depends_on:
      - postgres
    environment:
      - LOAD_EX=n
      - EXECUTOR=Local
    volumes:
      - ./dags:/usr/local/airflow/dags
      # Uncomment to include custom plugins
      # - ./plugins:/usr/local/airflow/plugins
    ports:
      - "8080:8080"
    links:
      - elasticsearch
    networks:
      - airflow_backand
    command: webserver
    healthcheck:
      test: ["CMD-SHELL", "[ -f /usr/local/airflow/airflow-webserver.pid ]"]
      interval: 30s
      timeout: 30s
      retries: 3
volumes:
  postgres_data:
  static_volume:
  media_volume:
  esdata:

networks:
    airflow_backand:
      driver: "host"
